# DataCamp Projects

This repository contains a collection of machine learning and data science projects completed for DataCamp. Each project demonstrates different techniques, workflows, and tools for solving real-world problems. Every folder includes its own dataset, Jupyter notebook, and README with specific instructions.

## Projects Included

- **From Data to Dollar - Insurance Charges**

  - Explores and predicts insurance charges using regression models.
  - Involves data cleaning, feature engineering, and model validation.
  - Tools used: pandas (data manipulation), numpy (numerical operations), scikit-learn (preprocessing, modeling, validation).
  - Files: `insurance.csv`, `validation_dataset.csv`, `notebook.ipynb`, `README.md`

- **Credit Card Approval**

  - Predicts credit card approvals using logistic regression and hyperparameter tuning (GridSearchCV).
  - Covers data preprocessing, model training, and evaluation.
  - Tools used: pandas, numpy, scikit-learn (model selection, preprocessing, metrics).
  - Files: `cc_approvals.data`, `notebook.ipynb`, `README.md`

- **Review Categorization**

  - Categorizes text reviews using natural language processing (NLP) and unsupervised learning (TF-IDF, KMeans clustering).
  - Includes text preprocessing, feature extraction, clustering, and analysis of top terms per category.
  - Tools used: pandas, numpy, scikit-learn (TF-IDF, clustering), nltk (tokenization, stopword removal).
  - Files: `reviews.csv`, `notebook.ipynb`, `README.md`

- **Word Frequency in My Blog**
  - Analyzes word frequency in blog posts written by Ankit Regmi ([blog](https://medium.com/@Ankit__/this-is-the-basic-outline-of-training-and-testing-a-model-84c2d3206bb8)).
  - Fetches blog content, parses HTML, preprocesses text, and visualizes word frequency.
  - Tools used: requests (fetch web content), BeautifulSoup (HTML parsing), nltk (tokenization, stopword removal), collections.Counter (word counting).
  - Files: `notebook.ipynb`, `README.md`

## How to Use

1. Explore each project folder for its own README and Jupyter notebook.
2. Open the notebook in Jupyter or VS Code and follow the step-by-step analysis.
3. Install required Python packages as listed in each project's README.

## Requirements

- Python 3.x
- See each project's README for specific package requirements (commonly pandas, numpy, scikit-learn, nltk, requests, beautifulsoup4)

## License

This repository is for educational purposes.

## Author

Ankit Regmi
